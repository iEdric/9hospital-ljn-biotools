{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\envs\\clhf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"olmOCR-7B-0225-preview\")\n",
    "model = AutoModelForImageTextToText.from_pretrained(\"olmOCR-7B-0225-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  9.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['就诊日期：2025-01-02 08:20  就诊科室：牙周病科  复诊\\n\\n姓名：[姓名]  性别：男  年龄：29岁\\n\\n主诉：牙周复诊\\n\\n现病史：牙周复查，1周前行全口龈上洁治+局部龈下刮治。\\n\\n既往史：否认高血压，糖尿病，心血管疾病等系统病史\\n\\n查体：PLI：2，可及龈下牙石，牙龈充血水肿，BOP（+），PD2-5mm，GR约0-2mm，7|6|7松动II°，5|4|3|2|1|2|3|4|5松动I°。\\n\\n辅助检查：全景片示：8|近中阻生。7|远中牙槽骨吸收达根长1/3。\\n\\n诊断：牙周病\\n\\n处理：1. OHI。\\n\\n2. 今行全口龈下刮治，3%H2O2冲洗，止血。告医嘱。\\n\\n3. 预约牙周复诊时间：[时间]。告知复诊需挂预约号，复诊当日按时到院。\\n\\n4. 建议口外科会诊拔除8|8。']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import base64\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, Qwen2VLForConditionalGeneration\n",
    "\n",
    "# Initialize the model\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\"olmOCR-7B-0225-preview\", torch_dtype=torch.bfloat16).eval()\n",
    "processor = AutoProcessor.from_pretrained(\"olmOCR-7B-0225-preview\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    \"\"\"将本地图片转换为base64字符串\"\"\"\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        return base64.b64encode(img_file.read()).decode('utf-8')\n",
    "\n",
    "# Directly use a local image file path\n",
    "image_path = \"images/t3.png\"\n",
    "image_base64 = image_to_base64(image_path)\n",
    "\n",
    "# Build the prompt, for demonstration, using a placeholder text.\n",
    "prompt = \"识别图片中所有信息\"\n",
    "\n",
    "# Build the full prompt\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"}},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Apply the chat template and processor\n",
    "text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "main_image = Image.open(image_path)\n",
    "\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=[main_image],\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = {key: value.to(device) for (key, value) in inputs.items()}\n",
    "\n",
    "# Generate the output\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    temperature=0.8,\n",
    "    max_new_tokens=1024,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Decode the output\n",
    "prompt_length = inputs[\"input_ids\"].shape[1]\n",
    "new_tokens = output[:, prompt_length:]\n",
    "text_output = processor.tokenizer.batch_decode(\n",
    "    new_tokens, skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(text_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已成功写入或追加到 results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def append_to_excel_safely(chat_response, excel_path):\n",
    "    try:\n",
    "        match = re.search(r\"```json\\s*(.*?)\\s*```\", chat_response, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(\"未找到有效的 JSON 数据\")\n",
    "        \n",
    "        json_str = match.group(1).strip()\n",
    "        # 将JSON字符串加载为Python字典\n",
    "        data_dict = json.loads(json_str)\n",
    "        # 将字典转换为DataFrame\n",
    "        df_new = pd.DataFrame([data_dict])\n",
    "        \n",
    "        if os.path.exists(excel_path):\n",
    "            # 如果文件存在，读取现有的Excel文件\n",
    "            df_existing = pd.read_excel(excel_path)\n",
    "            \n",
    "            # 确保所有列都在最终的DataFrame中\n",
    "            all_columns = sorted(set(df_existing.columns.union(df_new.columns)), key=lambda x: (x in df_existing.columns, x))\n",
    "            df_existing = df_existing.reindex(columns=all_columns, fill_value='')\n",
    "            df_new = df_new.reindex(columns=all_columns, fill_value='')\n",
    "            \n",
    "            # 避免重复添加相同的数据\n",
    "            df_combined = pd.concat([df_existing, df_new[~df_new.isin(df_existing.to_dict('list')).all(axis=1)]], ignore_index=True)\n",
    "        else:\n",
    "            df_combined = df_new\n",
    "        \n",
    "        # 写入Excel文件\n",
    "        df_combined.to_excel(excel_path, index=False, sheet_name='Sheet1', engine='openpyxl')\n",
    "        print(f\"数据已成功写入或追加到 {excel_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"发生错误：{e}\")\n",
    "\n",
    "# 示例调用\n",
    "chat_response = \"```json\\n{\\\"Image_Name\\\": \\\"example1.jpg\\\", \\\"Text_Output\\\": \\\"A d22og\\\", \\\"AI_Response\\\": \\\"It's a cute22 dog.\\\"}\\n```\"\n",
    "excel_path = 'results.xlsx'\n",
    "append_to_excel_safely(chat_response, excel_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clhf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
